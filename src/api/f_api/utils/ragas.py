from __future__ import annotations

from typing import Any

from langchain_core.documents import Document
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langsmith import Client
from langsmith.utils import LangSmithError
from ragas.testset.evolutions import multi_context, reasoning, simple
from ragas.testset.generator import TestDataset, TestsetGenerator

from f_api import config as cfg

generator_llm = ChatOpenAI(model=cfg.RAGAS_GENERATOR_MODEL)
critic_llm = ChatOpenAI(model=cfg.RAGAS_CRITIC_MODEL)
embeddings = OpenAIEmbeddings(model=cfg.RAGAS_EMBEDDINGS_MODEL)


def build_documents_tests(documents: list[Document], tests_per_doc: int = 3) -> None:
    docs_prep = prepare_documents(documents)
    testset = generate_ragas_testset(docs_prep, tests_per_doc)
    # upload_to_gcs(testset._to_records())
    save_as_dataset(testset)

def prepare_documents(documents: list[Document]) -> list[Document]:
    documents_prep = documents.copy()

    for document in documents_prep:
        document.metadata["filename"] = document.metadata["source"]

    return documents_prep

def generate_ragas_testset(
    documents: list[Document],
    tests_per_doc: int,
) -> TestDataset:
    test_size = tests_per_doc * len(documents)

    generator = TestsetGenerator.from_langchain(
        generator_llm,
        critic_llm,
        embeddings
    )

    return generator.generate_with_langchain_docs(
        documents,
        test_size=test_size,
        distributions={
            simple: 0.5,
            reasoning: 0.25,
            multi_context: 0.25,
        },
    )

def save_as_dataset(testset: TestDataset) -> None:
    client = Client()
    dataset_name = "synthetic-testset"

    try:
        dataset = client.read_dataset(dataset_name=dataset_name)
    except LangSmithError:
        dataset = client.create_dataset(
            dataset_name=dataset_name,
            description="Questions and answers generated by RAGAS.",
        )

    for record in testset._to_records():
        metadata = build_metadata(record)
        client.create_example(
            inputs={"question": record["question"]},
            outputs={"answer": record["ground_truth"]},
            metadata=metadata,
            dataset_id=dataset.id,
        )

def build_metadata(record: dict[str, Any]) -> dict[str, Any]:
    metadata = record.get("metadata")

    if isinstance(metadata, list):
        metadata = metadata[0]

    if not isinstance(metadata, dict):
        metadata = {}

    new_metadata: dict[str, Any] = metadata.copy()

    if "evolution_type" in record:
        new_metadata["evolution_type"] = record["evolution_type"]

    return new_metadata

# def upload_to_gcs(test_records: list[dict[str, Any]]) -> None:
#     newline_json = '\n'.join(json.dumps(d) for d in test_records)
#
#     storage_client = storage.Client()
#     bucket = storage_client.bucket(cfg.GCP_BUCKET_NAME)
#
#     blob_uuid = str(uuid.uuid4())
#     blob_dest_name = f"tests/{blob_uuid}.json"
#     blob = bucket.blob(blob_dest_name)
#
#     blob.upload_from_string(newline_json)
